{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading from both training_dataset.csv and test_dataset.csv \n",
    "#to perform m-estimate Naive Bayes and test the classification accuracy\n",
    "train_data = pd.read_csv('training_dataset_NB-Mounik.csv')\n",
    "test_data = pd.read_csv('test_dataset_NB-Mounik.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating function for performing m-estimate Naive Bayes and calculating the classification accuracy\n",
    "#Function will take training_dataset and test_dataset as input and provide the classification accuracy as output\n",
    "def nb_me_model(traindf,testdf):\n",
    "    \n",
    "    #Splitting test_dataset in two datasets where test_x dataset will have all the features \n",
    "    #and test_y dataset will have all the class labels so that we can calculate the classification accuracy later \n",
    "    #by comparing the output class label (from model) and original class label (from test_y)\n",
    "    testdf_x = testdf.iloc[:,:-1]\n",
    "    testdf_y = testdf.iloc[:,-1]\n",
    "    \n",
    "    #Calculating prior probability of each class in training_dataset by counting the occurence of each class \n",
    "    #(2 classes - 'edible' and 'poisonous') and dividing it by total number of instances in training_dataset\n",
    "    count_edible = len(traindf[traindf.iloc[:,-1] == 'edible'])\n",
    "    count_poison = len(traindf[traindf.iloc[:,-1] == 'poisonous'])    \n",
    "    prior_edible = count_edible/len(traindf)\n",
    "    prior_poison = count_poison/len(traindf)\n",
    "    \n",
    "    #Creating nested empty dictionaries for storing the likelihood probabilities of each feature values for each class\n",
    "    likelihood = {'edible':{},'poisonous':{}}\n",
    "    \n",
    "    #Iterating through each columns of training_dataset,except last column (class label) for calculating likelihood probability\n",
    "    for col in traindf.columns[:-1]:\n",
    "        \n",
    "        #Creating further nested empty dictionaries for storing the likelihood probability of each value\n",
    "        #of a feature while iterating through all the features in the training_dataset\n",
    "        likelihood['edible'][col] = {}\n",
    "        likelihood['poisonous'][col] = {}\n",
    "        \n",
    "        #Extracting unique values of each feature from training_dataset and storing them in the featval list\n",
    "        featval = list(traindf[col].unique())\n",
    "        \n",
    "        #Considering the m as number of possible values of the feature for m-estimate Naive Bayes\n",
    "        #Considering the p as uniform prior i.e (1 / number of possible values of the feature) for m-estimate Naive Bayes\n",
    "        m = len(featval)\n",
    "        p = 1/len(featval)\n",
    "        \n",
    "        #Iterating through each unique value of a feature for calculating likelihood probability\n",
    "        for value in featval:\n",
    "            \n",
    "            #Calculating occurence of each value of feature for the given class label \n",
    "            count_fv_edible = len(traindf[(traindf[col] == value) & (traindf.iloc[:,-1] == 'edible')])\n",
    "            count_fv_poison = len(traindf[(traindf[col] == value) & (traindf.iloc[:,-1] == 'poisonous')])\n",
    "            \n",
    "            #Calculating likelihood probability for each value of feature by adding m-estimate weight\n",
    "            #and storing them in the likelihood dictionary in a given nested dictionary\n",
    "            likelihood['edible'][col][value] = (count_fv_edible + (m*p))/(count_edible + m)\n",
    "            likelihood['poisonous'][col][value] = (count_fv_poison + (m*p))/(count_poison + m)\n",
    "            \n",
    "        #Emptying featval list for storing the new unique values of next feature in next iteration   \n",
    "        featval = []    \n",
    "    \n",
    "    #Creating empty list for storing the output class label of test_x dataset\n",
    "    classification = []\n",
    "    \n",
    "    #Iterating through each row of test_x dataset for classifying through m-estimate Naive Bayes\n",
    "    for row in range(0,len(testdf_x)):\n",
    "        \n",
    "        #Storing prior probabilities in two classify variables which will help in further calculation of posterior probability\n",
    "        classify_edible = prior_edible\n",
    "        classify_poison = prior_poison\n",
    "        \n",
    "        #Iterating through each feature in test_x dataset to calculate the posterior probability of each classes\n",
    "        #by multiplying the already stored prior probability with likelihood of each feature value for a given class\n",
    "        for feature in testdf_x.columns:\n",
    "            classify_edible *= likelihood['edible'][feature][testdf_x[feature].iloc[row]]\n",
    "            classify_poison *= likelihood['poisonous'][feature][testdf_x[feature].iloc[row]]\n",
    "       \n",
    "        #Comparing both posterior probabilities (2 classes - 'edible' and 'poisonous') and assigning\n",
    "        #maximum probability to a given instance by appending the output class label in separate list\n",
    "        if classify_edible > classify_poison:\n",
    "            classification.append('edible')\n",
    "        else:\n",
    "            classification.append('poisonous')\n",
    "    \n",
    "    #Calculating accuracy by comparing test_y dataset (original class label) with classification list (output class label)\n",
    "    #Initializing variable to count the total number of correct class labels while doing comparison\n",
    "    count_correct_class = 0\n",
    "    \n",
    "    #Iterating through each row in test_y dataset\n",
    "    for i in range(len(testdf_y)):\n",
    "        \n",
    "        #Comparing both original class label (from test_y dataset) and output class label (from classification list)\n",
    "        #If matches, count of correct class label will be incremented by 1\n",
    "        if testdf_y[i] == classification[i]:\n",
    "            count_correct_class += 1\n",
    "    \n",
    "    #Printing overall accuracy by calculating percentage of total number of correct class labels \n",
    "    #from total number of class labels in a test dataset\n",
    "    print('Overall Accuracy of m-estimate Naive Bayes model:', (count_correct_class/len(testdf_y))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of m-estimate Naive Bayes model: 94.0\n"
     ]
    }
   ],
   "source": [
    "#Passing both training_dataset and test_dataset to nb_me_model function \n",
    "#to check the overall accuracy of m-estimate Naive Bayes model\n",
    "nb_me_model(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
